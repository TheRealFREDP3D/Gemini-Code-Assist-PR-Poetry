# Required: GitHub token for accessing repository data
GITHUB_TOKEN=your_github_token_here

# Optional: LLM Provider API Keys (handled by LiteLLM)
# LiteLLM will automatically look for standard environment variables for different providers.
# Ensure the correct one is set for the model you choose via the --model argument.
# Examples:
# GOOGLE_API_KEY=your_google_api_key_here
# OPENAI_API_KEY=your_openai_api_key_here
# ANTHROPIC_API_KEY=your_anthropic_api_key_here
# COHERE_API_KEY=your_cohere_api_key_here
# Add other keys as needed for your chosen provider.
# Refer to LiteLLM documentation for specific provider environment variable names:
# https://docs.litellm.ai/docs/providers

# Optional: LiteLLM Logging (uncomment to enable for debugging LiteLLM calls)
# LITELLM_LOGGING=True
# LITELLM_LOG=DEBUG
# LITELLM_STREAMING_LOG=DEBUG # For debugging streaming responses, if applicable
# LITELLM_DISABLE_TELEMETRY=True # Optional: Disable LiteLLM telemetry
